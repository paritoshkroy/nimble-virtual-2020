---
title: "Strategies for improving MCMC"
subtitle: "NIMBLE 2020 Virtual Workshop"
author: "NIMBLE Development Team"
date: "June 2020"
output:
  slidy_presentation: default
  html_document:
    code_folding: show
---
<style>
slides > slide {
  overflow-x: auto !important;
  overflow-y: auto !important;
}
</style>

<style>
slides > slide {
  overflow-x: auto !important;
  overflow-y: auto !important;
}
</style>

```{r setup, include=FALSE}
library(nimble)
has_compareMCMCs <- require(compareMCMCs)
if(!has_compareMCMCs)
  warning("This Rmd file uses package compareMCMCs from github.  Sections using it will be skipped.")
has_rjags <- require(rjags)
if(!has_rjags)
  warning("This Rmd file uses package rjags.  Sections using it will be skipped.")
doComparisons <- TRUE
runExercise <- FALSE
```

# Overview

Some strategies for improving MCMC

 - Customize sampler choices. E.g.,
    - Try blocking correlated parameters.
    - Try sampling standard deviations on a log scale.
    - Try slice samplers instead of Metropolis-Hastings.
    - Try multiple samplers for slow-mixing parameters.
 - Reparameterize
    - Center covariates
    - Centered versus non-centered random effects
    - Rotated coordinates to reduce posterior correlation
 - (Advanced; tomorrow) Write new samplers that take advantage of particular model structures
 
 - Rewrite the model to reduce dependencies
 - Vectorize declarations to improve computational efficiency
 - Marginalize to remove parameters

# Load the Deer E. cervi example for later:

```{r load_Ecervi_example}
source(file.path("..", "examples", "DeerEcervi", "load_DeerEcervi.R"), 
       chdir = TRUE)
```

# Sampler choices and centering covariates or random effects  (1)

Sampler choices:

- Blocking can help when parameters are correlated *given other parameters*.
    - If parameters are *marginally correlated* but *conditionally independent*, blocking will not help.
    - This occurs if parameters are marginally correlated only because both they depend on something else.
- Slice sampling can help mix a parameter at some computational cost.
- Sampling standard deviations on a log scale can help, especially when there is posterior support near 0.
- Model-specific understanding can yield good sampling strategies.

# Sampler choices and centering covariates or random effects (2)

Centering refers to two issues:

- Centering of covariates as they are provided for the analysis.
    - Think of $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$. 
    - If the $x_i$ are not centered, then considering $\beta_1 \rightarrow \beta_1'$ is also like adding $(\beta_1' - \beta_1) \bar{x}$ to the intercept.
    - A standard result in linear regression is that estimates of $\beta_0$ and $\beta_1$ are correlated.
    - Centering $x_i$ around its mean removes the posterior correlation between $\beta_0$ and $\beta_1$.
    - In our example, we centered `Length`, but not separately for each sex.
    
- Centering of random effects around 0 or around a prediction from fixed effects.
    - Not relevant for our example.
    - Theory shows either parameterization can be better, depending on the model and data.
    
FIXME: Should be give some non-run illustration?

# Sampler choices and centering covariates or random effects (2)

Example: We'll run the examples of different samplers from the previous model **without centered `Length`**.

### Artifically un-center length to make blocking more interesting
```{r}
DEconstants_uncentered <- DEconstants # Artificially un-center Length
DEconstants_uncentered$cLength <- DeerEcervi$Length # cLength is now mis-named, 
                                                    # but it's easier than new model code.
```

```{r, echo=FALSE}
DEcode2 <- nimbleCode({
  for(i in 1:2) {
    length.effect[i] ~ dnorm(0, 1.0E-6) # precisions
    sex.effect[i] ~ dnorm(0, 1.0E-6)
  }
  farm.sd ~ dunif(0, 20)
  farm.precision <- 1/(farm.sd*farm.sd)

  for(i in 1:num.farms) {
    farm.effect[i] ~ dnorm(0, farm.precision) # precision
  }

  for(i in 1:num.animals) {
    logit(disease.probability[i]) <- 
      sex.effect[ sex[i] ] +
      length.effect[ sex[i] ]*cLength[i] +
      farm.effect[ farm.ids[i] ]
    Ecervi.01[i] ~ dbern(disease.probability[i])
  }
})
```

### Make `nimbleMCMCdefs`

```{r, eval=(has_compareMCMCs&doComparisons)}
nimbleMCMCdefs = list(
  nimble_RWblock = function(model) { # Input should be a model
    mcmcConf <- configureMCMC(model)
    mcmcConf$removeSamplers(c('sex.effect','length.effect'))
    mcmcConf$addSampler(target = c('sex.effect[1]', 'length.effect[1]'),
                        type = "RW_block",
                        control = list(adaptInterval = 20, tries = 2))
    mcmcConf$addSampler(target = c('sex.effect[2]', 'length.effect[2]'),
                        type = "RW_block",
                        control = list(adaptInterval = 20, tries = 2))
    mcmcConf                         # Output should be an MCMC configuration 
  },
  nimble_AFSSblock = function(model) {
    mcmcConf <- configureMCMC(model)
    mcmcConf$removeSamplers(c('sex.effect','length.effect'))
    mcmcConf$addSampler(target = c('sex.effect[1]', 'length.effect[1]'),
                        type = "AF_slice",
                        control = list(sliceAdaptFactorInterval = 20))
    mcmcConf$addSampler(target = c('sex.effect[2]', 'length.effect[2]'),
                        type = "AF_slice",
                        control = list(sliceAdaptFactorInterval = 20))
    mcmcConf                         # Output should be an MCMC configuration 
  }
)
```

### Call `compareMCMCs` for nimble cases (uncentered)


```{r, eval = (has_compareMCMCs&doComparisons)}
set.seed(123)
DEinits_vals <- DEinits1()
DEinits_vals_uncentered <- DEinits_vals
DEinits_vals_uncentered$sex.effect <- c(-8, -8)
mcmcResults_nimble_uncentered <- compareMCMCs(
  modelInfo = list(code = DEcode1, 
                   data = list(Ecervi.01 = DeerEcervi$Ecervi.01),
                   constants = DEconstants_uncentered,
                   inits = DEinits_vals_uncentered),
  ## monitors ## Use default monitors: top-level parameters
  MCMCs = c('nimble',
            'nimble_slice',
            'nimble_RWblock',    # Name matches nimbleMCMCdefs list name
            'nimble_AFSSblock'), # Ditto
  nimbleMCMCdefs = nimbleMCMCdefs,
  MCMCcontrol = list(niter = 50000, burnin = 5000)
)
```

### Call `compareMCMCs` for JAGS (uncentered)

```{r, include=FALSE}
mcmcResults_jags_uncentered <- list()
```

```{r, eval=(has_rjags&doComparisons)}
mcmcResults_jags_uncentered <- compareMCMCs(
  modelInfo = list(code = DEcode2, # JAGS-compatible
                   data = list(Ecervi.01 = DeerEcervi$Ecervi.01),
                   constants = DEconstants_uncentered, # centered
                   inits = DEinits_vals_uncentered),
  ## monitors ## Use default monitors: top-level parameters
  MCMCs = c('jags'),
  MCMCcontrol = list(niter = 50000, burnin = 5000)
)
```

#### Combine and visualize results (uncentered)

```{r, eval=doComparisons}
mcmcResults_uncentered <- c(mcmcResults_nimble_uncentered, mcmcResults_jags_uncentered) ## These are lists of MCMCresult objects
make_MCMC_comparison_pages(mcmcResults_uncentered, modelName = "Deer_Ecervi_uncentered")
```

#### Results 

Results are [here](Deer_Ecervi_uncentered.html).

# Think like a graph: reducing dependencies

Consider a basic state-space model.

Observation equation: $y_t \sim f(y_t | x_t)$.  (Parameters are not shown.)

State equation: $x_t \sim g(x_t | x_t-1)$

Two equivalent ways to write state-space models:

1. Process-noises are random variables.  States are deterministic given process noises. 

```{r}
code_heavy <- nimbleCode({
  for(t in 1:n) 
    y[t] ~ dnorm(x[t], sd = sigma)
  for(t in 2:n) {
    x[t] <- x[t-1] + eps[t-1]
    eps[t] ~ dnorm(0, sd = omega)
  }
})
```

2. States are random variables.

```{r}
code_light <- nimbleCode({
  for(t in 1:n) 
    y[t] ~ dnorm(x[t], sd = sigma)
  for(t in 2:n)
    x[t] ~ dnorm(x[t-1], sd = omega)
})
```

# Think like a graph: reducing dependencies (2)

```{r}
n <- 20
m_heavy <- nimbleModel(code_heavy, 
                       data = list(y = rnorm(n)), 
                       constants = list(n = n))
m_light <- nimbleModel(code_light, 
                       data = list(y = rnorm(n)), 
                       constants = list(n = n))
```

What calculations are required to update `eps[18]` or `eps[1]` compared to `x[18]` or `x[1]`?

```{r}
m_heavy$getDependencies('eps[18]')
m_light$getDependencies('x[18]')

m_heavy$getDependencies('eps[1]')
m_light$getDependencies('x[1]')
```

# Think like a graph: when to vectorize

Vectorizing some calculations:

- Can make code more compact.
- Can make model and MCMC building and compiling faster (fewer nodes).
- Can improve MCMC efficiency, but sometimes not by much (less looping over nodes).
- Can hurt MCMC efficiency if done in the wrong places (if unneeded dependencies are introduced).

```{r}
code <- nimbleCode({
  intercept ~ dnorm(0, sd = 1000)
  slope ~ dnorm(0, sd = 1000)
  sigma ~ dunif(0, 100)
  predicted.y[1:4] <- intercept + slope * x[1:4] # vectorized node
  for(i in 1:4) {
    y[i] ~ dnorm(predicted.y[i], sd = sigma)
  }
})
model <- nimbleModel(code, data = list(y = rnorm(4)))

model$getDependencies('slope')
```

Here sampling of `slope` (and `intercept`) will probably be a bit more efficient because of the vectorized definition of `predicted.y`, since all observations depend on `slope` (and `intercept`). 

We avoid some overhead by having one `predicted.y[1:4]` node rather than four `predicted.y[1], ..., predicted.y[4]` nodes.

Another (manual) step would be to create a user-defined vectorized `dnorm` distribution so `y[1:4]` is a vector node. 

# Think like a graph: when not to vectorize

However, if `x[2]` (and the other 'x's) were a scalar parameter (in this case a random effect), vectorization is likely a bad idea. Any update for `x[2]` will calculate `predicted.y[1:4]` and `y[1],...,y[4]` when only `predicted.y[2]` and `y[2]` need to be calculated.

```{r}
code <- nimbleCode({
  intercept ~ dnorm(0, sd = 1000)
  slope ~ dnorm(0, sd = 1000)
  sigma ~ dunif(0, 100)
  predicted.y[1:4] <- intercept + slope * x[1:4] # vectorized node
  for(i in 1:4) {
    x[i] ~ dnorm(0, 1)   # scalar random effects
    y[i] ~ dnorm(predicted.y[i], sd = sigma)
  }
})
model <- nimbleModel(code, data = list(y = rnorm(4)))

model$getDependencies('x[2]')
```

In this case, vectorization has made more dependencies for `x[2]` than should be necessary.  This would result in wasted computation during MCMC sampling.

# Marginalization

In a hierarchical model, one can *in principle* always integrate over latent states. However only under certain situations can one do those integrals in closed form (analytically).

Analytic integration is always possible in conjugate situations. For example:

$$ y_i \sim N(\mu_i, \sigma^2); i=1,\ldots,n $$
$$ \mu_i \sim N(\mu_0, \sigma_0^2),  i=1,\ldots,n $$

Here there is one latent state per observation. We can do MCMC here, but it involves a large number of parameters, n+3.

If we marginalize:

  - We reduce the total number of computations done at each step of the MCMC.
  - We reduce the dimensionality of the parameter space needing exploration.
  - In some cases the complexity of calculating the marginalized density offsets some of the benefits above.

Here's the marginalized result, with only 3 parameters.

$$ y_i \sim N(\mu_0, \sigma^2 + \sigma_0^2) $$

(If we want inference on $\mu_i, i=1,\ldots,n$ we need to sample the latent states conditional on the data and the MCMC draws of $\mu_0, \sigma_0^2, \sigma^2$.)

# Generalizing the Deer example

Suppose we wanted more flexibility than assuming a normal distribution for the farm effects in the Deer example.

We could use a two-component normal mixture. In BUGS/JAGS, a standard way to do this is to introduce a latent indicator for each farm indicating which component it is in.

It would be hard to constrain the mixture to have mean zero, so we'll move the intercept for sex 1 into the mixture.

```{r}
DEcodeFlex <- nimbleCode({
  for(i in 1:2) {
    # Priors for intercepts and length coefficients for sex = 1,2
    sex.effect[1] <- 0    # constraint to allow mixture to have non-zero mean
    sex.effect[2] ~ dnorm(0, sd = 1000)
    length.effect[i] ~ dnorm(0, sd = 1000)
  }
  
  # Priors for farm random effects
  # 'Manual' inclusion of bivariate normal mixture
  for(i in 1:num.farms) {
    farm.effect[i] ~ dnorm(mu[ind[i]+1], sd = sigma[ind[i]+1])
    ind[i] ~ dbern(pi)
  }
  for(i in 1:2) {
    mu[i] ~ dnorm(0, sd = 1000)
    sigma[i] ~ dunif(0, 20)
  }
  pi ~ dbeta(1, 1)   # same as dunif(0,1) but conjugacy will be detected
  
  # logit link and Bernoulli data probabilities
  for(i in 1:num.animals) {
    logit(disease.probability[i]) <- 
      sex.effect[ sex[i] ] +
      length.effect[ sex[i] ]*cLength[i] +
      farm.effect[ farm.ids[i] ]
    Ecervi.01[i] ~ dbern(disease.probability[i])
  }
})
```

Note: here `ind[i]` is a non-constant index (unlike its use earlier). It's a latent state, subject to MCMC sampling.

# Mixture models: identifiability

In mixture models, the meaning of the components can change - we could have:

$$ \pi = 0.4 $$ $$ \mu_1 = -2, \sigma_1 = 1 $$ $$ \mu_2 = 1, \sigma_2 = 3 $$

or

$$ \pi = 0.6 $$ $$ \mu_1 = 1, \sigma_1 = 3 $$ $$  \mu_2 = -2, \sigma_2 = 1 $$

This is fine if we don't care about interpretability (though it makes assessing MCMC mixing difficult).

We could also add a constraint (which will in this case remove conjugacy) to the model code:

```
constrain_means ~ dconstraint(mu[1] < mu[2])
```

Then we would include `constrain_means = 1` in the `data` list.

# Marginalization in the Deer example

We can always integrate over finite discrete random variables by summation, so we can integrate over the `ind[i]` variables, which take values of 0 or 1.

The bivariate normal mixture density is: $$ \pi N(\mu_1, \sigma_1) + (1-\pi) N(\mu_2, \sigma_2) $$

In BUGS/JAGS, one needs to use the "zeros trick" with a Poisson distribution and an 'observation' set to 0 to incorporate a non-standard density. That requires some gymnastics and adds nodes to the model graph.

In NIMBLE, we write a user-defined distribution using a nimbleFunction. Let's ignore the details for now and just focus on writing the density calculations. 

```{r}
dnormmix2 <- nimbleFunction(
  run = function(x = double(0), prob = double(0), 
                 mean = double(1), sd = double(1), 
                 log = logical(0, default = 0)) {
    
    returnType(double(0))
    # generally we want to calculate probability (density) on a 
    # log scale, but here that won't work.
    dens <- prob     * dnorm(x, mean[1], sd[1]) + 
            (1-prob) * dnorm(x, mean[2], sd[2])  
    if(log) 
      return(log(dens)) else return(dens)
  })
```

```{r, include=FALSE}
# only needed for Rmd compilation; not needed for regular usage.
assign('dnormmix2', dnormmix2, .GlobalEnv)
# 'r' simulation function not required but included here because of Rmd compilation issues.
rnormmix2 <- nimbleFunction(
  run = function(n = integer(0), prob = double(0), 
                 mean = double(1), sd = double(1)) {
  # dummy code    
  returnType(double(0))
  return(0)
})
assign('rnormmix2', rnormmix2, .GlobalEnv)
```

# Using the new distribution

One can then immediately use the distribution in a model. NIMBLE will compile the user-defined distribution together with everything else, as if `dnormmix2` were a distribution that NIMBLE provides.

```{r}
DEcodeFlexMarg <- nimbleCode({
  # Priors for intercepts and length coefficients for sex = 1,2
  sex.effect[1] <- 0    # constraint to allow mixture to have non-zero mean
  sex.effect[2] ~ dnorm(0, sd = 1000)
  for(i in 1:2) {
    length.effect[i] ~ dnorm(0, sd = 1000)
  }
  
  # Priors for farm random effects (centered on the 'baseline' sex)
  for(i in 1:num.farms) {
    farm.effect[i] ~ dnormmix2(pi, mu[1:2], sigma[1:2])
  }
  for(i in 1:2) {
    mu[i] ~ dnorm(0, sd = 1000)
    sigma[i] ~ dunif(0, 20)
  }
  pi ~ dbeta(1, 1)
  
  # logit link and Bernoulli data probabilities
  for(i in 1:num.animals) {
    logit(disease.probability[i]) <- 
      sex.effect[ sex[i] ] +
      length.effect[ sex[i] ]*cLength[i] +
      farm.effect[ farm.ids[i] ]
    Ecervi.01[i] ~ dbern(disease.probability[i])
  }
})
```

We can just create, compile, and use the model. 

```{r}
DEconstants <- list(num.farms = 24,
                    num.animals = 826,
                    cLength = DeerEcervi$cLength,
                    sex = DeerEcervi$Sex,
                    farm.ids = DeerEcervi$farm.ids)
DEdata <- list(Ecervi.01 = DeerEcervi$Ecervi.01)

DEinits <- function() {
  list(sex.effect = c(0, 0), 
       length.effect = c(0, 0),
       pi = runif(1),
       mu = rnorm(2),
       sigma = rep(1, 2),
       farm.effect = rnorm(24, 0, 1) )       
}

set.seed(1)
model <- nimbleModel(DEcodeFlexMarg, data = DEdata, constants = DEconstants)
model$setInits(DEinits())

model$calculate('farm.effect')
cModel <- compileNimble(model)
cModel$calculate('farm.effect')
```

FIXME: decide whether to actually run MCMC on these model variations

# Exercise

```{r, eval=runExercise}
DEconstants <- list(num.farms = 24,
                    num.animals = 826,
                    cLength = DeerEcervi$cLength,
                    sex = DeerEcervi$Sex,
                    farm.ids = DeerEcervi$farm.ids)
DEdata <- list(Ecervi.01 = DeerEcervi$Ecervi.01)

DEinits <- function() {
  list(sex.effect = c(0, 0), 
       length.effect = c(0, 0),
       farm.sd = 1,
       farm.effect = rnorm(24, 0, 1) )       
}

set.seed(1)
model <- nimbleModel(DEcode1, data = DEdata, constants = DEconstants)
model$setInits(DEinits())
cModel <- compileNimble(model)

conf <- configureMCMC(model)
conf$addMonitors('farm.effect')
mcmc <- buildMCMC(conf)
cmcmc <- compileNimble(mcmc, project = model)
samples <- runMCMC(cmcmc, niter = 5000, nburnin = 0)
```
