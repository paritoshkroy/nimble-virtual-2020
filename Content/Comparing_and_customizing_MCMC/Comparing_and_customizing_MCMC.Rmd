---
title: "Comparing and customizing MCMC in `nimble`"
author: "Perry de Valpine"
date: "June 2020"
output:
  slidy_presentation: default
  beamer_presentation: default
---
<style>
slides > slide {
  overflow-x: auto !important;
  overflow-y: auto !important;
}
</style>


```{r loadLibs, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE)
doMCMC <- FALSE
library(nimble)
if(!require(mvtnorm))
  warning("This Rmd file needs package mvtnorm.")
if(!require(coda))
  warning("This Rmd file needs package coda")
```


Agenda
=====

1. How we compare MCMC kernels
    * MCMC efficiency
2. How MCMC works: an introduction to different samplers
    - Mixing vs. computational cost
3. Modifying an MCMC configuration in `nimble`
4. Using `compareMCMCs`

Load the Deer E. cervi example for later:
=====
```{r setup}
source(file.path("..", "examples", "DeerEcervi", "load_DeerEcervi.R"), 
       chdir = TRUE)
set.seed(123)
DEmodel1 <- nimbleModel(DEcode1,
                        constants = DEconstants,
                        data = list(Ecervi.01 = DeerEcervi$Ecervi.01),
                        inits = DEinits1())
```

Bayes' law (conditional probability)
=====

In a hierarchical model, we typically have:

- params: top-level parameters, e.g. coefficients and std. deviations.
- states: random effects or latent states, e.g. farm effects
- data

\[
[\mbox{params, states | data}] = \frac{[\mbox{data | states, params}][\mbox{states | params}] [\mbox{params}]}{[\mbox{data}]}
\]

- $[\cdot]$ indicates probability density or mass.
- Denominator is hard to calculate but it is a constant.
- I will refer to the numerator = $[\mbox{data, states, params}]$ as the "model calculations."

Monte Carlo samples of the posterior: Toy example
=====

- Toy example: slope and intercept of a simple linear model with some simulated data.
- See Rmd file for source code.

```{r lmModel, include=FALSE}
lmCode <- nimbleCode({
  sigma ~ dunif(0, 20)
  intercept ~ dnorm(0, sd = 100)
  slope ~ dnorm(0, sd = 100)
  for(i in 1:n) {
    y[i] ~ dnorm(intercept + slope * x[i], sd = sigma)
  }
})
n <- 5
lmModel <- nimbleModel(lmCode, 
                       constants = list(n = n))
lmModel$slope <- 0.6
lmModel$intercept <- 10
lmModel$sigma <- 0.2
lmModel$x <- seq(0, 1, length = n)
lmModel$calculate()
set.seed(0)
lmModel$simulate('y')
lmModel$setData('y')
# {
#   plot(lmModel$x, lmModel$y, pch = 19)
#   abline(lm(lmModel$y ~ lmModel$x))
# }
```

```{r show-lm-data}
data.frame(x = lmModel$x, y = lmModel$y)
```

Monte Carlo samples of the posterior: Toy example
=====

Here is the true posterior density (assuming flat or effectively flat priors).

```{r calc-lm-posterior, include=FALSE}
log_posterior_numerator <- function(params) {
  lmModel$intercept <- params[1]
  lmModel$slope <- params[2]
  lmModel$calculate()
}
optim_map <- optim(c(10, 0.8), log_posterior_numerator, control = list(fnscale = -1))
optim_map$par
lmFit <- lm(lmModel$y ~ lmModel$x)
lmCoef <- coefficients(summary(lm(lmModel$y ~ lmModel$x))) ## Check that they match mle.
lmCoef
## Make a grid +/- 3 standard errors around the MLE
intercept_grid <- lmCoef['(Intercept)', 'Estimate'] +
  lmCoef['(Intercept)', 'Std. Error'] * seq(-3, 3, length = 21)
slope_grid <- lmCoef['lmModel$x', 'Estimate'] +
  lmCoef['lmModel$x', 'Std. Error'] * seq(-3, 3, length = 21)
llh_surface <- matrix(0, nrow = length(intercept_grid), 
                      ncol = length(slope_grid))
for(i in seq_along(intercept_grid))
  for(j in seq_along(slope_grid))
    llh_surface[i, j] <- log_posterior_numerator(c(intercept_grid[i], slope_grid[j]))
library(mvtnorm)
## we will "cheat" and use the mle
samples <- rmvnorm(1000, mean = lmCoef[, "Estimate"], sigma = vcov(lmFit))
```

```{r contour-lm-1, echo=FALSE}
contour(intercept_grid, slope_grid, llh_surface, 
        levels = optim_map$value - 0.01 - 0:5,
        main = "posterior density contours",
        xlab = "intercept", ylab = "slope")
```

Monte Carlo samples of the posterior: Toy example
=====

Our goal is a Monte Carlo sample from the posterior:

```{r contour-lm-2, echo=FALSE}
{
  contour(intercept_grid, slope_grid, llh_surface, 
        levels = optim_map$value - 0.01 - 0:5,
        main = "posterior log density contours",
        xlab = "intercept", ylab = "slope")
  points(samples, pch = '.', col = 'red')
}
```

MCMC kernel
=====

In this section:

- $\theta$: All parameters and states being sampled.
- $\theta_{i}$: Parameter (dimension) i of $\theta$. 
- $\theta^{(k)}$: Sample from iteration $k$.  This is the $k$-th row of MCMC output.

An *MCMC kernel* comprises one or more samplers that define $P(\theta^{(k+1)} | \theta^{(k)})$.

- $P(\theta^{(k+1)} | \theta^{(k)})$ is the distribution of one row of MCMC output given the previous row.
- Informally, today, "an MCMC" = "an MCMC kernel".
- An *MCMC sampler* updates one or more dimensions of $\theta$.
- Samplers are sometimes called "updaters".
- Kernels are sometimes called "samplers" This is reasonable (because a sampler is a kernel for its dimension(s)), but confusing. Today:
    - An MCMC (kernel) comprises one or more samplers.
    - An MCMC samples all desired dimensions (parameters or states).
    - A sampler samples a subset of desired dimensions.
- The posterior distribution is sometimes called the "target distribution".

MCMC kernel
=====
A `nimble` MCMC is an ordered set of samplers.

Example:

- Sampler 1: $(\theta_1^{(k)}, \theta_2^{(k)}, \theta_3^{(k)}, \theta_4^{(k)}) \rightarrow (\theta_1^{(k+1)}, \theta_2^{(k)}, \theta_3^{(k)}, \theta_4^{(k)})$
- Sampler 2: $(\theta_1^{(k+1)}, \theta_2^{(k)}, \theta_3^{(k)}, \theta_4^{(k)}) \rightarrow (\theta_1^{(k+1)}, \theta_2^{(k+2)}, \theta_3^{(k+2)}, \theta_4^{(k)})$
- Sampler 3: $(\theta_1^{(k+1)}, \theta_2^{(k+1)}, \theta_3^{(k+1)}, \theta_4^{(k)}) \rightarrow (\theta_1^{(k+1)}, \theta_2^{(k+1)}, \theta_3^{(k+1)}, \theta_4^{(k+1)})$

MCMC kernel
=====

Let's see nimble's default samplers for the E. cervi example.  Later we will cover modification of the MCMC configuration.

```{r mcmcConf}
mcmcConf <- configureMCMC(DEmodel1)
mcmcConf$printSamplers()
```

MCMC efficiency
=====

Mixing and computation time are both important to MCMC performance.

Let's get an MCMC sample for the E. cervi example.

```{r runMCMC, eval=doMCMC}
mcmcConf$addMonitors("farm.effect")
DEmcmc1 <- buildMCMC(mcmcConf)
compiled <- compileNimble(DEmodel1, DEmcmc1)
DEsamples <- runMCMC(compiled$DEmcmc1, niter = 10000, nburnin = 1000)
```

Better vs. worse mixing
=====

Mixing and computation time are both important to MCMC performance.

*Do not get excited about an MCMC just because it runs quickly.*

Mixing refers to how "quickly" (per iteration, not clock time) the MCMC moves around the posterior ("target distribution").

Let's see better vs. worse mixing:
```{r plot-samples, eval=doMCMC}
plot(DEsamples[,"length.effect[1]"], type = 'l') ## Happens to mix well
plot(DEsamples[,"sex.effect[1]"], type = 'l')    ## Doesn't mix as well
```

Measuring mixing as effective sample size (ESS)
=====

- *Effective sample size (ESS)* is the equivalent number of
independent samples in an MCMC chain for one parameter.

### What does "equivalent number of independent samples" mean?

- If `p[i]` were drawn independently (m samples), we could say:

$\mbox{Var}[\overline{p[i]}] = \mbox{Var}[ \frac{1}{m} \sum_{i = 1}^m p[i] ]= \frac{\mbox{Var} \left[ p[i] \right]}{m}$

- Instead, we have

$\mbox{Var}[\overline{p[i]}] = \frac{\mbox{Var}[p \left[i] \right]}{\mbox{ESS}}$

where ESS is the *Effective Sample Size*.

Examples of effective sample size
=====

The `effectiveSize` function of library `coda` gives one estimator of ESS.  (Library `mcmcse` has other estimators.)

Each dimension (parameter or state) has a different ESS.  (There are recent methods defining a multivariate ESS.)

```{r ESS, eval=doMCMC}
dim(DEsamples) ## Independent samples would have ESS=9000
effectiveSize(DEsamples)
```

We can see that the ESS is considerably smaller than the number of samples.

MCMC Efficiency (as the parameter level)
=====

MCMC efficiency = $\frac{\mbox{effective sample size (ESS)}}{\mbox{computation time}}$

- This is the number of effectively independent samples generated per time (second).
- ESS is different for every parameter.
- MCMC Pace = 1 / MCMC Efficiency
- Computation time is the same for every parameter: the total time.
- We do not count setup steps like model building and compilation as
  part of computation time. We are more interested in the final MCMC
  performance.
- Whether to include "burn-in" time depends on the goal.  Today we won't.
- One needs a reasonable sample just to get a reasonable estimate of ESS.
- We generally do not thin when comparing methods because thinning always removes some information from a sample.  People might disagree on this choice.
- Sometimes fancy samplers are too slow (computationally costly) to be worthwhile.

A single number (at the kernel level): Minimum MCMC efficiency
=====

- We want a single number to measure the performance of an MCMC.
- Often there are many fast-mixing parameters and one or a few
slow-mixing ones.
- We need all parameters to be mixed well to rely on results.
- Therefore our single measure of efficiency is:

**Net MCMC efficiency = Minimum MCMC efficiency over all parameters**

Why we don't care as much about mean MCMC efficiency
=====

- It is tempting to think mean (across parameters) of MCMC efficiency is a good measure of overall performance.
- If some parameters are mixing very well and others very poorly, you should not feel the results are acceptable.


How MCMC works: samplers compose a kernel
=====

- Not *why* it works, but *what* it does.
- MCMC generates a sequentially dependent sample whose stationary distribution is the "target" distribution (e.g. posterior).
- There are lots of ways to do this, all within the MCMC family of algorithms.
- "univariate" or "scalar" samplers update one dimension.
- "block" samplers update multiple dimensions together.

How MCMC works: calculations for a sampler
=====

- Linear model example: Say current values are slope = 0.2, intercept = 10.4.
- Say the next sampler will update the intercept.
- The log posterior density for intercept, up to a constant, given slope = 0.2, is:

```{r lmConditional, echo=FALSE}
intercept_grid_given_slope <- seq(10.1, 10.6, length = 31)
llh_surface_given_slope <- apply(matrix(intercept_grid_given_slope), 1, 
                                 function(int) log_posterior_numerator(c(int, 0.2)))
{
  plot(intercept_grid_given_slope, exp(llh_surface_given_slope), type = 'l',
     main = "Conditional posterior density (up to a constant) for slope = 0.2",
     ylab = "Conditional posterior density (up to a constant)",
     xlab = "intercept")
  lines(c(10.4, 10.4), c(0, 0.1), col = 'red')
  legend("topleft", col = "red", legend = "current value", lty = 1)
}
```

Choosing a new value depends only on **ratios** of the surface.

How MCMC works: calculations for a sampler
=====

$Y$ = Data

$\theta$ = Parameters and states, everything being sampled

$\theta_1$ = current value of dimension being updated

$\theta_1'$ = possible new value of dimension being updated

$\theta_F$ = current values of all other dimensions (fixed).

Model calculations are $[Y, \theta] = [Y, (\theta_1', \theta_F)]$.

The needed ratio for many methods is
\[
\frac{[Y, (\theta_1', \theta_F)]}{[Y, (\theta_1, \theta_F)]} = \frac{(\mbox{Factors using } \theta_1')(\mbox{Factors not using } \theta_1')}{(\mbox{Factors using } \theta_1)(\mbox{Factors not using } \theta_1)} = \frac{\mbox{Factors using } \theta_1'}{\mbox{Factors using } \theta_1} 
\]

Conclusion: only the part of $[Y, \theta]$ that involves a particular parameter(s) needs to be calculated.

Different methods require different numbers of calculations of $[Y, \theta]$, so some are slow and some are fast.

Some methods also use derivatives of $[Y, \theta]$.  (These aren't in `nimble` yet but will be in the future.)


Gibbs (conjugate) samplers
=====

- Possible when we can write $[\theta_1 | \theta_F, Y]$ analytically.
- This only works for particular prior-posterior combinations.
- Despite sounding simple, there is some computational cost (different than shown above).
- Both JAGS and nimble use conjugate samplers by default when available.
- We will not spend more time on these.

Adaptive Random-walk Metropolis-Hastings samplers
=====

```{r, echo=FALSE}
theta1 <- seq(0.5, 5, length = 200)
targetDist <- 0.1 * dnorm(theta1, 2, 0.5)
current <- 1.3
proposalDist <- dnorm(theta1, current, sd = 0.1)
proposalDisplayScale <- max(proposalDist)/max(targetDist)
proposalDist <- proposalDist / proposalDisplayScale
proposal <- 1.5
nextTargetDist <- 0.03 * dnorm(theta1, 2.4, 0.2)
{
  plot(theta1, targetDist, type = 'l', col = 'black',
       main = "Random-walk Metropolis-Hastings",
       ylab = "Target and proposal distributions (scaled)",
       xlab = expression(theta[1]))
  points(theta1, proposalDist, type = 'l', col = 'blue')
  points(theta1, nextTargetDist, type = 'l', col = 'goldenrod')
  points(current, 0.1 * dnorm(current, 2, 0.5), pch = 19, col = 'red')
  points(proposal, 0.1 * dnorm(proposal, 2, 0.5), pch = 8, col = 'red')
  lines(c(current, current), c(0, 0.1 * dnorm(current, 2, 0.5)), col = 'red')
  lines(c(proposal, proposal), c(0, 0.1 * dnorm(proposal, 2, 0.5)), col = 'red')
  legend("topright", lty = c(1,1,0,0, 1), 
         pch = c(NA, NA, 19, 8, NA), 
         col = c('black','blue','red','red', 'goldenrod'),
         legend = c('target distribution', 'proposal distribution (scaled)', 'current value', 'proposal value', 'next iteration target distribution' ))
}
```

- Current value the parameter is $\theta_1$.
- Propose a new value $\theta_1' \sim N(\theta, \nu)$ (blue).  This is centered on the current value, so we call it a "random walk".
- How to accept or reject $\theta_1'$?
     - Calculate ratio of $[Y, (\theta_1', \theta_F)] / [Y, (\theta_1, \theta_F)]$ (using only needed factors). 
     - If the ratio is $\gt 1$, accept $\theta'$.
     - Otherwise that ratio is the "acceptance probability".
     - Draw a uniform random variate to decide whether to accept or reject.
     - Rejection means $\theta_1^{(k+1)} = \theta_1^{(k)}$
- We have skipped some generality here.
     - For non-symmetric proposals, there is a ratio of proposal densities involved too.
- Computational cost is either 
     - two evaluations of $[Y, (\theta_1', \theta_F)]$ (only the parts that depend on $\theta_1$), or
     - one evaluation of $[Y, (\theta_1', \theta_F)]$ (ditto) and some copying to save previous values.
- How to choose $\nu$? 
     - By "adaptation".  The algorithm increases or decreases $\nu$ to achieve theoretically derived optimal accpetance rate.  
- Generalizes to multivariate (block) sampling.
- This method is computationally cheap but may or may not mix well.

Slice samplers
=====

```{r, echo = FALSE}
theta1grid <- seq(0.5, 5, length = 200)
targetDist <- function(theta1) {0.1 * dnorm(theta1, 2, 0.5)}
targetDistGrid <- targetDist(theta1grid)
current <- 1.3
origCurrent <- current
update <- function(current, targetDist, mean) {
  currentF <- targetDist(current)
  u <- runif(1, 0, currentF)
  leftBound <- uniroot(function(x) (targetDist(x)-u), lower = -10, upper = mean)$root
  rightBound <- uniroot(function(x) (targetDist(x)-u), lower = mean, upper = 10)$root
  updated <- runif(1, leftBound, rightBound)
  list(lower = leftBound, upper = rightBound, u = u, currentF = currentF, updated = updated)
}
set.seed(345)
u1 <- update(current, targetDist, 2)
u2 <- update(u1$updated, targetDist, 2)
u3 <- update(u2$updated, targetDist, 2)
slicePlotter <- function(u, current) {
  points(current, targetDist(current), pch = 19, col = 'red')
  lines(c(current, current), c(0, targetDist(current)), col = 'red')
  points(current, u$u, pch = 17, col = 'purple')
  points(u$lower, u$u, pch= 3, col = 'blue')
  points(u$upper, u$u, pch = 3, col = 'blue')
  lines(c(u$lower, u$upper), c(u$u, u$u), type = 'l', col = 'blue')
  points(u$updated, u$u, pch = 8, col = 'red')
  lines(c(u$updated, u$updated), c(0, u$u), type = 'l', col = 'red')
  u$updated
}
sliceLegend <- function() {
  legend("topright",
         lty = c(1, 0, 0, 1, 0),
         legend = c('target dist', 'current value', 'vertical uniform draw', 'horizontal range', 'new value (horizontal uniform draw)'),
         pch = c(NA, 19, 17, 3, 8),
         col = c('black', 'red', 'purple','blue', 'red'))
}
```

```{r, echo=FALSE}
{
  plot(theta1grid, targetDistGrid, type = 'l', col = 'black',
       main = 'slice sampler',
       ylab = "target distribution",
       xlab = expression(theta[1]))
  current <- origCurrent
  for(u in list(u1)) {
    current <- slicePlotter(u, current)
  }
  sliceLegend()
}
```

- Based on current $\theta_1$, pick an auxiliary "height" (uniform draw).
- Determine lower and upper bounds for $\theta_1$ as shown.
- Draw new value of $\theta_1$ uniformly between those bounds.


```{r, echo=FALSE}
{
  plot(theta1grid, targetDistGrid, type = 'l', col = 'black',
       main = 'slice sampler',
       ylab = "target distribution",
       xlab = expression(theta[1]))
  current <- u1$updated
  for(u in list(u2)) {
    current <- slicePlotter(u, current)
  }
  sliceLegend()
}
```


```{r, echo=FALSE}
{
  plot(theta1grid, targetDistGrid, type = 'l', col = 'black',
       main = 'slice sampler',
       ylab = "target distribution",
       xlab = expression(theta[1]))
  current <- u2$updated
  for(u in list(u3)) {
    current <- slicePlotter(u, current)
  }
  points(theta1grid, 0.05*dnorm(theta1grid, 3, .4), type = 'l', col = 'goldenrod')
  sliceLegend()
  legend("topleft", col = "goldenrod", pch = NA, lty = 1, legend = "new target distribution")
}
```

Slice sampling computational costs
=====
- Determining the lower and upper bounds is not simple!
- The target distribution changes every time (due to updating of other parameters).
- Bounds must be determined by "stepping out" until the target height is below the chosen level (blue).
- Computational cost can be *many* evaluations of $[Y, (\theta_1, \theta_F)]$ (again, only the necessary factors).

Multivariate random-walk Metropolis-Hastings samplers
=====

- Make proposals in multiple dimensions using multivariate normal proposals.

- Works ok in a moderate number of dimensions.

- Does not work well in many dimensions.

- In more dimensions, it is harder to make large proposal steps.

- Adaptation must determine good scale and correlations for proposals.  Finding these can be slow.

- May work well for a small number of correlated dimensions.

- If posterior dimensions are only weakly correlated, it is usually better to alternate dimensions.

- Computational cost depends on which parts of $[Y, \theta]$ are needed.

    - Some parameters might share the same calculations.
    - Some parameters might require different calculations.

- May not work well when the scale of interest for different dimensions is very different.

    - nimble generates a message about this.


Multivariate slice samplers
=====

* Choose new parameter axes (still orthogonal).

    - Think of principal components analysis (PCA) for an analogy.
    - You can think of these as rotated parameter coordinates.
    - You can think of these as linear combinations of parameters.
    
* Use a slice sampler in the new parameter axes.

* Adaptation needs to discover good axes.

* Computational cost is at least as large as slice samplers in each original parameter.  

* Computational cost is higher if different parameters require different model calculations (different parts of $[Y, \theta]$).

* Mixing is generally improved if posterior is correlated.

Other samplers in nimble
=====
- binary (for Bernoulli variables)
- categorical (these are *costly*).
- posterior predictive sampler (for no dependencies)
- elliptical slice sampler (for certain MVN cases).
- CAR (conditional autoregression model) normal sampler
- CAR proper sampler
- random-walk multinomial sampler
- random-walk Dirichlet sampler
- cross-level sampler
- `RW_llFunction` A random-walk Metropolis-Hastings that calls any log-likelihood function you provide.
- Particle MCMC samplers.

Other samplers (not currently in nimble)
=====

Samplers that use derivatives of $[\mbox{data, parameters}]$:

- Hamiltonian Monte Carlo

    - Good mixing but at very high computational cost.
    
- Langevin samplers

    - Use one gradient evaluation to make a good MH proposal density.
    
These samplers will be supported in `nimble` in the coming year.  They work now in development versions.

Modifying an MCMC configuration in `nimble`
=====


Using `compareMCMCs`
=====

